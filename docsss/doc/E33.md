# Livrable E3 — Développement d’API, Supervision et Livraison Continue (Projet csv_analyzer)

Page de garde
- Titre: Livrable E3 — API, IA, Supervision et CI/CD
- Projet: csv_analyzer / AutoML-Gr4-1
- Auteur: [Votre Nom]
- Date: [JJ/MM/AAAA]
- Version: 1.0

Table des matières
1. Introduction
2. Expression des besoins
3. Développement de l’API
   3.1 Spécifications fonctionnelles
   3.2 Spécifications techniques
   3.3 Architecture technique
   3.4 Environnement de développement
   3.5 Tests des endpoints
   3.6 Intégration
   3.7 Authentification
   3.8 Communication des endpoints
   3.9 Adaptation de l’interface
   3.10 Tests d’intégration
4. Supervision du modèle d’IA
   4.1 Métriques
   4.2 Outils et intégration
   4.3 Restitution (dashboards)
   4.4 Tests/Validation de la supervision
5. Tests automatisés du modèle d’IA
   5.1 Situations de tests
   5.2 Outils
   5.3 Interprétation des résultats
6. Livraison continue du modèle d’IA
   6.1 Définition de la chaîne
   6.2 Déclencheurs
   6.3 Configuration
7. Documentation
8. Perspectives et améliorations
9. Conclusion
Annexes

Références de fichiers du projet
- <mcfile name="urls.py" path="csv_analyzer/urls.py"></mcfile>
- <mcfile name="urls.py" path="csv_processor/urls.py"></mcfile>
- <mcfile name="metrics.py" path="csv_processor/metrics.py"></mcfile>
- <mcfile name="ci.yml" path=".github/workflows/ci.yml"></mcfile>
- <mcfile name="docker-compose.yml" path="docker-compose.yml"></mcfile>
- <mcfile name="prometheus.yml" path="prometheus.yml"></mcfile>
- <mcfile name="test_views.py" path="csv_processor/tests/test_views.py"></mcfile>
- <mcfile name="test_models.py" path="csv_processor/tests/test_models.py"></mcfile>
- <mcfile name="csv_analyzer.json" path="grafana/dashboards/csv_analyzer.json"></mcfile>
- <mcfile name="mlflow_utils.py" path="csv_processor/mlflow_utils.py"></mcfile>

1. Introduction
Ce livrable présente l’API de traitement CSV et d’intégration IA, la supervision de l’application et des modèles (métriques, tableaux de bord), ainsi que la chaîne de livraison continue. Il s’appuie sur les éléments réellement présents dans le projet: documentation OpenAPI/Swagger, métriques Prometheus, dashboards Grafana, suivi d’expériences MLflow, tests automatisés et pipeline CI.

Objectifs:
- Exposer une API REST documentée.
- Permettre l’upload, le nettoyage, l’exploration, l’export et l’entraînement/évaluation de modèles.
- Superviser application et modèles via Prometheus/Grafana et MLflow.
- Qualifier via tests et livrer via CI/CD.

2. Expression des besoins
- Manipuler des fichiers CSV: upload, vue tabulaire, opérations colonnes/lignes, nettoyage, export.
- Intégrer un module IA: entraînement (classification/régression), test du modèle, sauvegarde, téléchargement.
- Documenter l’API: schéma OpenAPI et UI Swagger pour l’équipe.
- Observabilité: métriques système/app, latence requêtes, métriques métiers CSV.
- Traçabilité IA: runs, métriques et artefacts via MLflow.
- Qualité: tests unitaires/intégration, sécurité de base, CI/CD.
Contraintes:
- Conteneurisation pour reproductibilité.
- Monitoring standard Prometheus/Grafana.
- Stockage local MLflow (artifact store mlruns).

3. Développement de l’API

3.1 Spécifications fonctionnelles
- Chargement CSV: téléverser un fichier, vérifier son format et stocker des métadonnées.
- Consultation: visualiser paginée, rechercher/filtrer, télécharger.
- Opérations données: supprimer ligne, ajouter/supprimer colonne, nettoyage.
- Export: CSV/JSON/Excel/PDF.
- IA: entraînement modèles (classification et régression), test/prédiction, sauvegarde/renommage/suppression modèle.
- Documentation: accès au schéma OpenAPI et Swagger UI.

3.2 Spécifications techniques
- Framework: Django + Django REST.
- Documentation: DRF Spectacular.
- Endpoints de documentation:
  - Schéma OpenAPI: /api/schema/
  - Swagger UI: /api/docs/
  (voir <mcfile name="urls.py" path="csv_analyzer/urls.py"></mcfile>)
- Exposition des métriques Prometheus: /metrics (voir <mcfile name="prometheus.yml" path="prometheus.yml"></mcfile> et <mcfile name="metrics.py" path="csv_processor/metrics.py"></mcfile>)
- Sérialisation/validation: serializers DRF (voir <mcfile name="serializers.py" path="csv_processor/serializers.py"></mcfile>).

3.3 Architecture technique
- Niveaux:
  - Présentation: Templates Django (upload, view, ml_results, test_model).
  - API: vues Django/DRF pour opérations CSV/IA.
  - IA: formation et tests (scikit-learn) avec journalisation MLflow.
  - Observabilité: Prometheus → collecte, Grafana → visualisation.
  - Stockages: media/ pour fichiers/artefacts, mlruns/ pour MLflow.
- Services conteneurisés:
  - web (Django, port 8000)
  - prometheus (9090)
  - grafana (3000)
  - node-exporter (9100)
  (voir <mcfile name="docker-compose.yml" path="docker-compose.yml"></mcfile>)

3.4 Environnement de développement
- Python et dépendances: <mcfile name="requirements.txt" path="requirements.txt"></mcfile>
- Lancement local:
  - python manage.py migrate
  - python manage.py runserver 0.0.0.0:8000
- Conteneurs:
  - docker compose up -d
- Accès docs API:
  - http://localhost:8000/api/docs/
  - http://localhost:8000/api/schema/

3.5 Tests des endpoints
- Tests automatisés des vues et comportements:
  - <mcfile name="test_views.py" path="csv_processor/tests/test_views.py"></mcfile>: authentification, upload CSV, visualisation, suppression de ligne, nettoyage, opérations colonnes, entraînement/test de modèles (cas valides et erreurs).
  - <mcfile name="test_models.py" path="csv_processor/tests/test_models.py"></mcfile>: création CSVFile et journalisation Operation.
- Stratégie: cas nominaux + données manquantes/invalides + modèles inexistants.

3.6 Intégration
- Routes projet:
  - <mcfile name="urls.py" path="csv_analyzer/urls.py"></mcfile> pour schéma et Swagger.
  - <mcfile name="urls.py" path="csv_processor/urls.py"></mcfile> pour les endpoints métier CSV/IA et exports.
- Gabarits UI: <mcfolder name="templates" path="templates/"></mcfolder> avec pages upload, view, ml_results, test_model.
- Stockage fichiers: <mcfolder name="media" path="media/"></mcfolder> (csv_files, exports, ml_models, predictions).

3.7 Authentification
- Pages utilisateurs: login, register, profile (voir <mcfolder name="templates/users" path="templates/users/"></mcfolder>).
- Les tests couvrent l’accès authentifié aux opérations sensibles (voir <mcfile name="test_views.py" path="csv_processor/tests/test_views.py"></mcfile>).

3.8 Communication des endpoints
- Découverte via Swagger UI: /api/docs/
- Échange JSON pour opérations API.
- Export multi-formats exposé par endpoints dédiés (CSV/JSON/Excel/PDF).
- Métriques Prometheus exposées en texte via /metrics.

3.9 Adaptation de l’interface
- Pages HTML existantes intègrent les actions clés: import CSV, aperçu, résultats ML (ml_results), test du modèle (test_model).
- Possibilité d’ajouter des boutons “Exporter”, “Nettoyer”, “Former/Test” mappés aux endpoints.

3.10 Tests d’intégration
- Pytest avec client HTTP (Django) vérifiant flux bout-en-bout: upload → opérations → entraînement → test → export.
- Couverture configurée dans pytest.ini.

4. Supervision du modèle d’IA

4.1 Métriques
- Système: CPU, mémoire, disque via Node Exporter.
- Application (voir <mcfile name="metrics.py" path="csv_processor/metrics.py"></mcfile>):
  - Compteurs/latence requêtes: django_request_total, django_request_latency_seconds
  - Métriques système (réexportées côté app): system_cpu_usage, system_memory_usage_bytes, system_disk_usage_bytes
  - Métriques métier CSV: csv_file_uploads_total, csv_file_size_bytes, csv_processing_time_seconds
- IA/Expérimentations:
  - Suivi d’entraînement et d’évaluation via MLflow (runs, métriques, artefacts; voir <mcfile name="mlflow_utils.py" path="csv_processor/mlflow_utils.py"></mcfile>).

4.2 Outils et intégration
- Prometheus:
  - Scrape /metrics sur web:8000 et node-exporter:9100
  - Configuration: <mcfile name="prometheus.yml" path="prometheus.yml"></mcfile>
- Grafana:
  - Dashboard dédié: <mcfile name="csv_analyzer.json" path="grafana/dashboards/csv_analyzer.json"></mcfile>
- MLflow:
  - Stockage local des runs: <mcfolder name="mlruns" path="mlruns/"></mcfolder>
  - Script d’aide: <mcfile name="start_mlflow.sh" path="start_mlflow.sh"></mcfile> (pour lancer un serveur MLflow si souhaité).

4.3 Restitution (dashboards)
- Prometheus → Status/Targets pour vérifier “UP”.
- Grafana → tableaux: latence requêtes, CPU/mémoire/disque, activité d’upload/traitement.
- MLflow → runs, métriques (accuracy, MAE/MSE/R2), artefacts modèles.

4.4 Tests/Validation de la supervision
- Vérifier exposition /metrics (HTTP 200 + contenu).
- Prometheus: targets UP, séries reçues.
- Grafana: panneaux alimentés (courbes non vides après activité).
- MLflow: runs créés après entraînement, métriques non vides, artefacts présents.

5. Tests automatisés du modèle d’IA

5.1 Situations de tests
- Données valides: formation/résultats attendus.
- Données incomplètes: message d’erreur contrôlé.
- Données invalides: validation et réponses 4xx/5xx adéquates.
- Modèle inexistant: gestion 404/400.
- Classification et Régression: prise en charge de plusieurs algorithmes.

5.2 Outils
- Pytest + Django Test Client (voir <mcfile name="test_views.py" path="csv_processor/tests/test_views.py"></mcfile>).
- Tests des modèles et journalisation (voir <mcfile name="test_models.py" path="csv_processor/tests/test_models.py"></mcfile>).

5.3 Interprétation des résultats
- Réussite: endpoints fiables et robustes → prêts pour intégration.
- Échec: logs pytest pour diagnostiquer, corrections ciblées (serializer/validation/erreurs).

6. Livraison continue du modèle d’IA

6.1 Définition de la chaîne
- Lint sécurité: Flake8 + Bandit.
- Tests: pytest + couverture.
- Build/push image: Docker vers GHCR.
- Jobs: voir <mcfile name="ci.yml" path=".github/workflows/ci.yml"></mcfile>.

6.2 Déclencheurs
- Sur push/PR main (configurable), exécution des jobs lint → tests → docker.

6.3 Configuration
- Docker:
  - <mcfile name="docker-compose.yml" path="docker-compose.yml"></mcfile>
  - Service web (Django) + Prometheus + Grafana + Node Exporter
- Prometheus:
  - <mcfile name="prometheus.yml" path="prometheus.yml"></mcfile>
- Variables sensibles: à fournir via secrets du dépôt/runner.

7. Documentation
- OpenAPI: /api/schema/
- Swagger UI: /api/docs/
- Guide utilisateur: <mcfile name="user_guide.md" path="user_guide.md"></mcfile>
- Rapport E3 (ce document), et autres livrables dans <mcfolder name="docsss/doc" path="docsss/doc/"></mcfolder>.

8. Perspectives et améliorations
- Authentification/Autorisations fines sur endpoints sensibles.
- Plus d’algorithmes (p. ex. Gradient Boosting en classification; forêts/algo avancés en régression).
- Enregistrement/chargement de modèles versionnés (MLflow Models Registry).
- Alerting Prometheus (alertmanager) + règles SLO/SLA.
- Tests E2E sur navigateur (Playwright/Cypress).
- Déploiement staging/prod via CD (GitHub Actions → serveur/container registry).

9. Conclusion
Le projet met à disposition une API complète pour manipuler des CSV et intégrer un pipeline IA, avec documentation interactive, supervision opérationnelle et suivi IA. Les tests automatisés et la CI garantissent la qualité et la répétabilité; la conteneurisation facilite l’exécution locale et l’observabilité.

Annexes

A. URLs utiles
- API Docs (Swagger): http://localhost:8000/api/docs/
- OpenAPI Schema: http://localhost:8000/api/schema/
- Prometheus: http://localhost:9090/
- Grafana: http://localhost:3000/
- Application (Django): http://localhost:8000/
- Endpoint métriques: http://localhost:8000/metrics

B. Extraits de configuration

prometheus.yml